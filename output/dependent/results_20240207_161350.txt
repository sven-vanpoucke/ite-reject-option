CHAPTER 1: INTRODUCTION
# This section introduces the purpose and background of the analysis.

In this analysis, we aim to evaluate the performance of different reject options for Information Treatment Effect (ITE) models.The ITE model predicts the individual treatment effects in a given dataset, providing valuable insights into the impact of interventions.
For your information, this file has been automatically generated on: 2024-02-07 16:13

CHAPTER 2: PREPROCESSING

# This section executes the data retrieval, preprocessing and splitting in a training and dataset.During the whole file, the used dataset is: twins

CHAPTER 3: MODEL TRAINING

# This section provides details about the model selection, training process, and any hyperparameter tuning.
The trained ITE model is a T-LEARNER.
The two individually trained models are: LogisticRegression

CHAPTER 4: PREDICT

# This section applies the trained models to our test_set. 
# We are able to predict the y_t0, y_t1 and ite 
CHAPTER 5: EVALUATE INDIVIDUAL LOGISTIC REGRESSION MODELS 

# This section evaluates the individually trained models (two as we used a T-learner). 
The used performance measures are: 

 - Confusion Matrix 
 - Accuracy: overal correctness of the model ((TP + TN) / (TP + TN + FP + FN)) 
 - Precision: It measures the accuracy of positive predictions (TP / (TP + FP)) 
 - Recall: ability of the model to capture all the relevant cases (TP / (TP + FN)) 
 - F1 Score It balances precision and recall, providing a single metric for model evaluation (2 * (Precision * Recall) / (Precision + Recall)) 
 - ROC 

Evaluation of the individual models based on the **training data**
Confusion Matrix:
+-----------------+---------------+---------------+
|     Metric      | Treated Group | Control Group |
+-----------------+---------------+---------------+
| True Positives  |     3704      |     3633      |
| False Positives |      138      |      112      |
| False Negatives |      363      |      409      |
| True Negatives  |      367      |      394      |
+-----------------+---------------+---------------+

Metrics:
+-----------+---------------+---------------+
|  Metric   | Treated Group | Control Group |
+-----------+---------------+---------------+
| Accuracy  |     0.89      |     0.89      |
| Precision |     0.73      |     0.78      |
|  Recall   |      0.5      |     0.49      |
|    F1     |     0.59      |      0.6      |
|    AUC    |     0.73      |     0.73      |
+-----------+---------------+---------------+


Evaluation of the individual models based on the **test data**
Confusion Matrix:
+-----------------+---------------+---------------+
|     Metric      | Treated Group | Control Group |
+-----------------+---------------+---------------+
| True Positives  |      902      |      941      |
| False Positives |      25       |      27       |
| False Negatives |      84       |      114      |
| True Negatives  |      98       |      89       |
+-----------------+---------------+---------------+

Metrics:
+-----------+---------------+---------------+
|  Metric   | Treated Group | Control Group |
+-----------+---------------+---------------+
| Accuracy  |      0.9      |     0.88      |
| Precision |      0.8      |     0.77      |
|  Recall   |     0.54      |     0.44      |
|    F1     |     0.64      |     0.56      |
|    AUC    |     0.76      |     0.71      |
+-----------+---------------+---------------+

CHAPTER 6: EVALUATE OVERALL ITE MODEL: PERFORMANCE 

# This section evaluates the overal performance of the ITE model.
The used performance measures are: 

 - Root Mean Squared Error (RMSE) of the ITE 
 - Accurate estimate of the ATE 
 - Accurancy of ITE


Root Mean Squared Error (RMSE) between the ite and ite_prob: 0.3131

The Actual Average Treatment Effect (ATE): -0.0158
The Predicted Average Treatment Effect (ATE): -0.0044
Accuracy of Average Treatment Effect (ATE): 0.0114


CHAPTER 7: EVALUATE OVERALL ITE MODEL: COST 

# This section evaluates the overal misclassification costs of the ITE model.
We make the matrix: Lost Cause, Sleeping Dog, Persuadable, Sure Thing 
Comment: 
 - Upper left cell: amount of cases that have outcome 0: no matter if you would treat or not 
   If treat, they stay alive, if no treat they also stay alive. 
 - Under right cell: amount of cases that have outcome 1: no matter if you would treat or not 
   If treat, they die, if no treat they also die. 
 - Upper right cell: amount of cases that have outcome 1 if treated, but outcome 0 if not treated 
   If treat, they die, if no treat they stay alive. 
 - Under left cell: amount of cases that have outcome 0 if treated, but outcome 1 if not treated 
   If treat, they stay alive, if no treat they die. 


Crosstab for y_t0 and y_t1:
┌────────┬───────┬───────┐
│   y_t0 │   0.0 │   1.0 │
├────────┼───────┼───────┤
│      0 │  1777 │    92 │
├────────┼───────┼───────┤
│      1 │   128 │   283 │
└────────┴───────┴───────┘

Crosstab for y_t0_pred and y_t1_pred:
┌─────────────┬───────┬───────┐
│   y_t0_pred │   0.0 │   1.0 │
├─────────────┼───────┼───────┤
│           0 │  2020 │    19 │
├─────────────┼───────┼───────┤
│           1 │    29 │   212 │
└─────────────┴───────┴───────┘

Total Misclassification Cost: 2160

CHAPTER 8: REJECTION 

# This section executes and reports metrics for ITE models with rejection.
# Every indicated change are in comparision to the base ITE model without rejection.

ARCHITECTURE TYPE 0: NO REJECTION -- BASELINE MODEL

              precision    recall  f1-score   support

          -1       0.07      0.02      0.03       128
           0       0.91      0.98      0.94      2060
           1       0.16      0.03      0.05        92

    accuracy                           0.89      2280
   macro avg       0.38      0.34      0.34      2280
weighted avg       0.83      0.89      0.85      2280

Accuracy: 0.9260
Rejection Rate: 0.0000
Micro TPR: 0.8890
Micro FPR: 0.0555
Macro TPR: 0.3433
Macro FPR: 0.3248
Micro Distance (3D ROC): 0.1241
Macro Distance (3D ROC): 0.7327

Improvements due to a rejection rate of 0.00%:
- Change of the Misclassification Cost: 0.00%
- Change of the ITE Accurancy: 0.00%
- Change of the 3D ROC (micro): 0.00%
- Change of the 3D ROC (macro): 0.00%

ARCHITECTURE TYPE 1: SEPARATED

REJECTION TYPE 1A: OUT OF DISRIBUTION

              precision    recall  f1-score   support

          -1       0.05      0.01      0.02       106
           0       0.90      0.98      0.94      1710
           1       0.25      0.04      0.07        79

    accuracy                           0.89      1895
   macro avg       0.40      0.34      0.34      1895
weighted avg       0.83      0.89      0.85      1895

Accuracy: 0.9272
Rejection Rate: 0.1689
Micro TPR: 0.8908
Micro FPR: 0.0546
Macro TPR: 0.3441
Macro FPR: 0.3261
Micro Distance (3D ROC): 0.2084
Macro Distance (3D ROC): 0.7517

Improvements due to a rejection rate of 16.89%:
- Change of the Misclassification Cost: 15.46%
- Change of the ITE Accurancy: 0.12%
- Change of the 3D ROC (micro): 40.47%
- Change of the 3D ROC (macro): 2.54%

REJECTION TYPE 1B: ONE CLASS CLASSIFICATION MODEL

              precision    recall  f1-score   support

          -1       0.05      0.01      0.02       106
           0       0.90      0.98      0.94      1710
           1       0.25      0.04      0.07        79

    accuracy                           0.89      1895
   macro avg       0.40      0.34      0.34      1895
weighted avg       0.83      0.89      0.85      1895

Accuracy: 0.9272
Rejection Rate: 0.1689
Micro TPR: 0.8908
Micro FPR: 0.0546
Macro TPR: 0.3441
Macro FPR: 0.3261
Micro Distance (3D ROC): 0.2084
Macro Distance (3D ROC): 0.7517

Improvements due to a rejection rate of 16.89%:
- Change of the Misclassification Cost: 15.46%
- Change of the ITE Accurancy: 0.12%
- Change of the 3D ROC (micro): 40.47%
- Change of the 3D ROC (macro): 2.54%

REJECTION TYPE 1B: ONE CLASS CLASSIFICATION MODEL using OCSVM

              precision    recall  f1-score   support

          -1       0.07      0.02      0.03        63
           0       0.91      0.98      0.95      1018
           1       0.17      0.03      0.05        38

    accuracy                           0.90      1119
   macro avg       0.38      0.34      0.34      1119
weighted avg       0.84      0.90      0.86      1119

Accuracy: 0.9309
Rejection Rate: 0.5092
Micro TPR: 0.8963
Micro FPR: 0.0518
Macro TPR: 0.3418
Macro FPR: 0.3291
Micro Distance (3D ROC): 0.5222
Macro Distance (3D ROC): 0.8949

Improvements due to a rejection rate of 50.92%:
- Change of the Misclassification Cost: 34.68%
- Change of the ITE Accurancy: 0.52%
- Change of the 3D ROC (micro): 76.24%
- Change of the 3D ROC (macro): 18.13%

REJECTION TYPE 1C: SCORE MODEL

 - Not done yet

              precision    recall  f1-score   support

          -1       0.05      0.01      0.02       106
           0       0.90      0.98      0.94      1710
           1       0.25      0.04      0.07        79

    accuracy                           0.89      1895
   macro avg       0.40      0.34      0.34      1895
weighted avg       0.83      0.89      0.85      1895

Accuracy: 0.9272
Rejection Rate: 0.1689
Micro TPR: 0.8908
Micro FPR: 0.0546
Macro TPR: 0.3441
Macro FPR: 0.3261
Micro Distance (3D ROC): 0.2084
Macro Distance (3D ROC): 0.7517

Improvements due to a rejection rate of 16.89%:
- Change of the Misclassification Cost: 15.46%
- Change of the ITE Accurancy: 0.12%
- Change of the 3D ROC (micro): 40.47%
- Change of the 3D ROC (macro): 2.54%

ARCHITECTURE TYPE 2: DEPENDENT

REJECTION TYPE 2A: REJECTION BASED ON PROBABILITIES BY MINIMIZING 3DROC 

VARIANT TYPE 2A I: OPTIMIZATION OF SINGLE BOUNDARIES BY MINIMIZING 3DROC 

ITE values witht a probability between the optimal underbound 0.3976480773675689 and the optimal upperbound 0.6023519226324311 are rejected 
              precision    recall  f1-score   support

          -1       0.09      0.01      0.02       116
           0       0.91      0.99      0.95      2003
           1       0.15      0.03      0.04        80

    accuracy                           0.90      2199
   macro avg       0.39      0.34      0.34      2199
weighted avg       0.84      0.90      0.87      2199

Accuracy: 0.9360
Rejection Rate: 0.0355
Micro TPR: 0.9040
Micro FPR: 0.0480
Macro TPR: 0.3415
Macro FPR: 0.3265
Micro Distance (3D ROC): 0.1130
Macro Distance (3D ROC): 0.7358

Improvements due to a rejection rate of 3.55%:
- Change of the Misclassification Cost: -2.52%
- Change of the ITE Accurancy: 1.07%
- Change of the 3D ROC (micro): -9.78%
- Change of the 3D ROC (macro): 0.43%

VARIANT TYPE 2A II: OPTIMIZATION OF DOUBLE BOUNDARIES BY MINIMIZING 3DROC  

ITE values witht a probability between the optimal underbound 0.45 and the optimal upperbound 0.55 are rejected 
              precision    recall  f1-score   support

          -1       0.08      0.02      0.03       124
           0       0.91      0.98      0.94      2048
           1       0.18      0.03      0.06        89

    accuracy                           0.89      2261
   macro avg       0.39      0.34      0.34      2261
weighted avg       0.83      0.89      0.86      2261

Accuracy: 0.9292
Rejection Rate: 0.0083
Micro TPR: 0.8939
Micro FPR: 0.0531
Macro TPR: 0.3447
Macro FPR: 0.3248
Micro Distance (3D ROC): 0.1190
Macro Distance (3D ROC): 0.7314

Improvements due to a rejection rate of 0.83%:
- Change of the Misclassification Cost: -1.50%
- Change of the ITE Accurancy: 0.35%
- Change of the 3D ROC (micro): -4.28%
- Change of the 3D ROC (macro): -0.17%

REJECTION TYPE 2A: REJECTION BASED ON PROBABILITIES BY MINIMIZING MISCLASSIFICATION COSTS 

ITE values witht a probability between the optimal underbound 0.3137613115788537 and the optimal upperbound 0.6862386884211463 are rejected 
              precision    recall  f1-score   support

          -1       0.00      0.00      0.00       103
           0       0.92      1.00      0.96      1902
           1       0.33      0.02      0.03        66

    accuracy                           0.92      2071
   macro avg       0.42      0.34      0.33      2071
weighted avg       0.85      0.92      0.88      2071

Accuracy: 0.9446
Rejection Rate: 0.0917
Micro TPR: 0.9169
Micro FPR: 0.0415
Macro TPR: 0.3377
Macro FPR: 0.3320
Micro Distance (3D ROC): 0.1305
Macro Distance (3D ROC): 0.7465

Improvements due to a rejection rate of 9.17%:
- Change of the Misclassification Cost: -3.45%
- Change of the ITE Accurancy: 1.97%
- Change of the 3D ROC (micro): 4.92%
- Change of the 3D ROC (macro): 1.86%


Table of test_set (First 20 rows)
+-----------+-----------+-----------+-----------+-----------+----------+----------+------+------+-----+-------------+---------------+----------+------------+-----------------+-------+------------------+------------------+---------------+----------+
| treatment | y_t1_pred | y_t1_prob | y_t0_pred | y_t0_prob | ite_pred | ite_prob | y_t0 | y_t1 | ite |  category   | category_pred | cost_ite | ite_reject | cost_ite_reject |  ood  | y_t1_reject_prob | y_t0_reject_prob | y_reject_prob | y_reject |
+-----------+-----------+-----------+-----------+-----------+----------+----------+------+------+-----+-------------+---------------+----------+------------+-----------------+-------+------------------+------------------+---------------+----------+
|     1     |    0.0    |  0.0061   |    0.0    |  0.0124   |   0.0    | -0.0063  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     1     |    1.0    |  0.5434   |    1.0    |  0.6367   |   0.0    | -0.0932  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Sure Thing   |    0     |     R      |        2        | False |       True       |       True       |     True      |   True   |
|     1     |    0.0    |  0.0914   |    0.0    |  0.1421   |   0.0    | -0.0506  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.1494   |    0.0    |  0.1784   |   0.0    | -0.0289  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.0148   |    0.0    |   0.024   |   0.0    | -0.0092  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     0     |    1.0    |  0.7949   |    1.0    |  0.8064   |   0.0    | -0.0115  | 1.0  | 1.0  | 0.0 | Sure Thing  |  Sure Thing   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.0509   |    0.0    |  0.0666   |   0.0    | -0.0157  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.3943   |    0.0    |  0.4325   |   0.0    | -0.0382  | 1.0  | 1.0  | 0.0 | Sure Thing  |  Lost Cause   |    0     |     R      |        2        | False |       True       |       True       |     True      |   True   |
|     1     |    0.0    |  0.0615   |    0.0    |  0.0907   |   0.0    | -0.0293  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.0611   |    0.0    |  0.0939   |   0.0    | -0.0328  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     1     |    0.0    |   0.273   |    0.0    |  0.2836   |   0.0    | -0.0106  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.0433   |    0.0    |  0.0654   |   0.0    |  -0.022  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.0049   |    0.0    |  0.0107   |   0.0    | -0.0058  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.0492   |    0.0    |  0.0821   |   0.0    |  -0.033  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.1568   |    0.0    |  0.1836   |   0.0    | -0.0268  | 0.0  | 1.0  | 1.0 | Persuadable |  Lost Cause   |    10    |    0.0     |       10        | False |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.2423   |    0.0    |  0.2382   |   0.0    |  0.0041  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.1384   |    0.0    |  0.1616   |   0.0    | -0.0232  | 1.0  | 1.0  | 0.0 | Sure Thing  |  Lost Cause   |    0     |    0.0     |        0        | True  |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.0658   |    0.0    |   0.048   |   0.0    |  0.0177  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.0816   |    0.0    |  0.1165   |   0.0    | -0.0349  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     1     |    0.0    |   0.018   |    0.0    |  0.0193   |   0.0    | -0.0013  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
+-----------+-----------+-----------+-----------+-----------+----------+----------+------+------+-----+-------------+---------------+----------+------------+-----------------+-------+------------------+------------------+---------------+----------+