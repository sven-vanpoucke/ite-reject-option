CHAPTER 1: INTRODUCTION

This file has been automatically generated on: 2024-02-06 22:55

This file has been generated on: 2024-02-06 22:55

CHAPTER 2: PREPROCESSING

The used dataset is: twins

CHAPTER 3: MODEL T-LEARNER

The used model is: LogisticRegression

CHAPTER 4: PREDICT

CHAPTER 5: EVALUATE INDIVIDUAL LOGISTIC REGRESSION MODELS 

Performance measurement: 

 - Confusion Matrix 
 - Accuracy: overal correctness of the model ((TP + TN) / (TP + TN + FP + FN)) 
 - Precision: It measures the accuracy of positive predictions (TP / (TP + FP)) 
 - Recall: ability of the model to capture all the relevant cases (TP / (TP + FN)) 
 - F1 Score It balances precision and recall, providing a single metric for model evaluation (2 * (Precision * Recall) / (Precision + Recall)) 
 - ROC 

Evaluation of the individual models based on the **training data**
Confusion Matrix:
+-----------------+---------------+---------------+
|     Metric      | Treated Group | Control Group |
+-----------------+---------------+---------------+
| True Positives  |     3651      |     3732      |
| False Positives |      131      |      107      |
| False Negatives |      347      |      413      |
| True Negatives  |      390      |      349      |
+-----------------+---------------+---------------+

Metrics:
+-----------+---------------+---------------+
|  Metric   | Treated Group | Control Group |
+-----------+---------------+---------------+
| Accuracy  |     0.89      |     0.89      |
| Precision |     0.75      |     0.77      |
|  Recall   |     0.53      |     0.46      |
|    F1     |     0.62      |     0.57      |
|    AUC    |     0.75      |     0.72      |
+-----------+---------------+---------------+


Evaluation of the individual models based on the **test data**
Confusion Matrix:
+-----------------+---------------+---------------+
|     Metric      | Treated Group | Control Group |
+-----------------+---------------+---------------+
| True Positives  |      940      |      888      |
| False Positives |      35       |      22       |
| False Negatives |      101      |      93       |
| True Negatives  |      130      |      71       |
+-----------------+---------------+---------------+

Metrics:
+-----------+---------------+---------------+
|  Metric   | Treated Group | Control Group |
+-----------+---------------+---------------+
| Accuracy  |     0.89      |     0.89      |
| Precision |     0.79      |     0.76      |
|  Recall   |     0.56      |     0.43      |
|    F1     |     0.66      |     0.55      |
|    AUC    |     0.76      |      0.7      |
+-----------+---------------+---------------+

CHAPTER 6: EVALUATE OVERALL ITE MODEL: PERFORMANCE 

Performance measurement: 
 - Root Mean Squared Error (RMSE) of the ITE 
 - Accurate estimate of the ATE 
 - Accurancy of ITE 



Root Mean Squared Error (RMSE) between the ite and ite_prob: 0.3258

The Actual Average Treatment Effect (ATE): -0.0092
The Predicted Average Treatment Effect (ATE): 0.0057
Accuracy of Average Treatment Effect (ATE): 0.0149


CHAPTER 7: EVALUATE OVERALL ITE MODEL: COST 

We make the matrix: Lost Cause, Sleeping Dog, Persuadable, Sure Thing 
Comment: 
 - Upper left cell: amount of cases that have outcome 0: no matter if you would treat or not 
   If treat, they stay alive, if no treat they also stay alive. 
 - Under right cell: amount of cases that have outcome 1: no matter if you would treat or not 
   If treat, they die, if no treat they also die. 
 - Upper right cell: amount of cases that have outcome 1 if treated, but outcome 0 if not treated 
   If treat, they die, if no treat they stay alive. 
 - Under left cell: amount of cases that have outcome 0 if treated, but outcome 1 if not treated 
   If treat, they stay alive, if no treat they die. 


Crosstab for y_t0 and y_t1:
┌────────┬───────┬───────┐
│   y_t0 │   0.0 │   1.0 │
├────────┼───────┼───────┤
│      0 │  1752 │   109 │
├────────┼───────┼───────┤
│      1 │   130 │   289 │
└────────┴───────┴───────┘

Crosstab for y_t0_pred and y_t1_pred:
┌─────────────┬───────┬───────┐
│   y_t0_pred │   0.0 │   1.0 │
├─────────────┼───────┼───────┤
│           0 │  2000 │    27 │
├─────────────┼───────┼───────┤
│           1 │    14 │   239 │
└─────────────┴───────┴───────┘

Total Misclassification Cost: 2305

CHAPTER 8: REJECTION 


ARCHITECTURE TYPE 1: SEPARATED


REJECTION TYPE 1A: OUT OF DISRIBUTION


              precision    recall  f1-score   support

          -1       0.10      0.01      0.02       106
           0       0.90      0.99      0.94      1725
           1       0.22      0.06      0.09        88

    accuracy                           0.89      1919
   macro avg       0.41      0.35      0.35      1919
weighted avg       0.83      0.89      0.85      1919

Accuracy: 0.9267
Rejection Rate: 0.1583
Micro TPR: 0.8900
Micro FPR: 0.0550
Macro TPR: 0.3510
Macro FPR: 0.3211
Micro Distance (3D ROC): 0.2005
Macro Distance (3D ROC): 0.7412

Improvements due to a rejection rate of 15.83%:
Change of the Misclassification Cost: -30.23%
Change of the ITE Accurancy: 0.29%
Change of the 3D ROC (micro): 36.40%
Change of the 3D ROC (macro): 2.19%

ARCHITECTURE TYPE 2: DEPENDENT


REJECTION TYPE 2A: REJECTION BASED ON PROBABILITIES BY MINIMIZING 3DROC 


VARIANT TYPE 2A I: OPTIMIZATION OF SINGLE BOUNDARIES BY MINIMIZING 3DROC 


ITE values witht a probability between the optimal underbound 0.41756018773499537 and the optimal upperbound 0.5824398122650046 are rejected 
              precision    recall  f1-score   support

          -1       0.14      0.01      0.02       118
           0       0.90      1.00      0.95      1984
           1       0.50      0.03      0.06        98

    accuracy                           0.90      2200
   macro avg       0.52      0.35      0.34      2200
weighted avg       0.85      0.90      0.86      2200

Accuracy: 0.9336
Rejection Rate: 0.0351
Micro TPR: 0.9005
Micro FPR: 0.0498
Macro TPR: 0.3452
Macro FPR: 0.3255
Micro Distance (3D ROC): 0.1167
Macro Distance (3D ROC): 0.7321

Improvements due to a rejection rate of 3.51%:
Change of the Misclassification Cost: -14.68%
Change of the ITE Accurancy: 1.03%
Change of the 3D ROC (micro): -9.25%
Change of the 3D ROC (macro): 0.97%

VARIANT TYPE 2A II: OPTIMIZATION OF DOUBLE BOUNDARIES BY MINIMIZING 3DROC  


ITE values witht a probability between the optimal underbound 0.45 and the optimal upperbound 0.55 are rejected 
              precision    recall  f1-score   support

          -1       0.11      0.01      0.02       124
           0       0.90      0.99      0.94      2017
           1       0.33      0.04      0.07       105

    accuracy                           0.89      2246
   macro avg       0.45      0.35      0.34      2246
weighted avg       0.83      0.89      0.85      2246

Accuracy: 0.9294
Rejection Rate: 0.0149
Micro TPR: 0.8940
Micro FPR: 0.0530
Macro TPR: 0.3464
Macro FPR: 0.3256
Micro Distance (3D ROC): 0.1194
Macro Distance (3D ROC): 0.7304

Improvements due to a rejection rate of 1.49%:
Change of the Misclassification Cost: -9.76%
Change of the ITE Accurancy: 0.58%
Change of the 3D ROC (micro): -6.77%
Change of the 3D ROC (macro): 0.74%

REJECTION TYPE 2A: REJECTION BASED ON PROBABILITIES BY MINIMIZING MISCLASSIFICATION COSTS 


ITE values witht a probability between the optimal underbound 0.47213130792215763 and the optimal upperbound 0.5278686920778424 are rejected 
              precision    recall  f1-score   support

          -1       0.08      0.01      0.01       129
           0       0.90      0.99      0.94      2032
           1       0.24      0.05      0.08       107

    accuracy                           0.89      2268
   macro avg       0.40      0.35      0.34      2268
weighted avg       0.82      0.89      0.85      2268

Accuracy: 0.9256
Rejection Rate: 0.0053
Micro TPR: 0.8884
Micro FPR: 0.0558
Macro TPR: 0.3477
Macro FPR: 0.3221
Micro Distance (3D ROC): 0.1248
Macro Distance (3D ROC): 0.7275

Improvements due to a rejection rate of 0.53%:
Change of the Misclassification Cost: -8.22%
Change of the ITE Accurancy: 0.18%
Change of the 3D ROC (micro): -2.14%
Change of the 3D ROC (macro): 0.35%


Table of test_set (First 20 rows)
+-----------+-----------+-----------+-----------+-----------+----------+----------+------+------+-----+-------------+---------------+----------+-------+------------+-----------------+------------------+------------------+---------------+----------+
| treatment | y_t1_pred | y_t1_prob | y_t0_pred | y_t0_prob | ite_pred | ite_prob | y_t0 | y_t1 | ite |  category   | category_pred | cost_ite |  ood  | ite_reject | cost_ite_reject | y_t1_reject_prob | y_t0_reject_prob | y_reject_prob | y_reject |
+-----------+-----------+-----------+-----------+-----------+----------+----------+------+------+-----+-------------+---------------+----------+-------+------------+-----------------+------------------+------------------+---------------+----------+
|     0     |    0.0    |  0.1078   |    0.0    |  0.1306   |   0.0    | -0.0227  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     | False |    0.0     |        0        |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.0354   |    0.0    |  0.0549   |   0.0    | -0.0195  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     | False |    0.0     |        0        |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.0218   |    0.0    |  0.0351   |   0.0    | -0.0133  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     | False |    0.0     |        0        |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.0062   |    0.0    |  0.0151   |   0.0    | -0.0088  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     | False |    0.0     |        0        |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.0085   |    0.0    |  0.0151   |   0.0    | -0.0067  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     | False |    0.0     |        0        |      False       |      False       |     False     |  False   |
|     1     |    1.0    |  0.6865   |    1.0    |  0.6298   |   0.0    |  0.0567  | 0.0  | 1.0  | 1.0 | Persuadable |  Sure Thing   |    10    | False |    0.0     |       10        |      False       |      False       |     False     |  False   |
|     1     |    1.0    |  0.8675   |    1.0    |  0.7646   |   0.0    |  0.1028  | 1.0  | 1.0  | 0.0 | Sure Thing  |  Sure Thing   |    0     | False |    0.0     |        0        |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.0455   |    0.0    |  0.0515   |   0.0    | -0.0061  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     | False |    0.0     |        0        |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.2265   |    0.0    |  0.3047   |   0.0    | -0.0781  | 1.0  | 1.0  | 0.0 | Sure Thing  |  Lost Cause   |    0     | False |    0.0     |        0        |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.0635   |    0.0    |  0.1064   |   0.0    | -0.0429  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     | True  |    0.0     |        0        |      False       |      False       |     False     |  False   |
|     1     |    1.0    |   0.908   |    1.0    |  0.8254   |   0.0    |  0.0825  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Sure Thing   |    0     | False |    0.0     |        0        |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.0216   |    0.0    |  0.0363   |   0.0    | -0.0148  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     | False |    0.0     |        0        |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.0831   |    0.0    |  0.1068   |   0.0    | -0.0237  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     | False |    0.0     |        0        |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.0312   |    0.0    |  0.0542   |   0.0    |  -0.023  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     | False |    0.0     |        0        |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.0292   |    0.0    |  0.0349   |   0.0    | -0.0057  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     | False |    0.0     |        0        |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.0445   |    0.0    |  0.0546   |   0.0    |  -0.01   | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     | False |    0.0     |        0        |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.1983   |    0.0    |  0.2415   |   0.0    | -0.0431  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     | False |    0.0     |        0        |      False       |      False       |     False     |  False   |
|     1     |    1.0    |  0.5441   |    0.0    |  0.4959   |   1.0    |  0.0482  | 1.0  | 1.0  | 0.0 | Sure Thing  |  Persuadable  |    5     | False |    1.0     |        0        |      False       |       True       |     False     |  False   |
|     0     |    0.0    |  0.0003   |    0.0    |  0.0008   |   0.0    | -0.0005  | 0.0  | 0.0  | 0.0 | Lost Cause  |  Lost Cause   |    0     | True  |    0.0     |        0        |      False       |      False       |     False     |  False   |
|     1     |    1.0    |  0.7786   |    1.0    |  0.7914   |   0.0    | -0.0128  | 1.0  | 1.0  | 0.0 | Sure Thing  |  Sure Thing   |    0     | True  |    0.0     |        0        |      False       |      False       |     False     |  False   |
+-----------+-----------+-----------+-----------+-----------+----------+----------+------+------+-----+-------------+---------------+----------+-------+------------+-----------------+------------------+------------------+---------------+----------+