CHAPTER 1: INTRODUCTION
# This section introduces the purpose and background of the analysis.

In this analysis, we aim to evaluate the performance of different reject options for Information Treatment Effect (ITE) models.The ITE model predicts the individual treatment effects in a given dataset, providing valuable insights into the impact of interventions.
For your information, this file has been automatically generated on: 2024-02-07 21:21
\Chapter 2: Preprocessing

# This section executes the data retrieval, preprocessing and splitting in a training and dataset.During the whole file, the used dataset is: TWINS

CHAPTER 3: Training of the ITE Model

# This section provides details about the model selection, training process, and any hyperparameter tuning.
The trained ITE model is a T-LEARNER.
The two individually trained models are: LogisticRegression

CHAPTER 4: Evaluate treated and control groups seperately

# This section evaluates the individually trained models (two as we used a T-learner).
The used performance measures are:

 - Confusion Matrix
 - Accuracy: overall correctness of the model ((TP + TN) / (TP + TN + FP + FN))
 - Precision: It measures the accuracy of positive predictions (TP / (TP + FP))
 - Recall: ability of the model to capture all the relevant cases (TP / (TP + FN))
 - F1 Score: It balances precision and recall, providing a single metric for model evaluation (2 * (Precision * Recall) / (Precision + Recall))
 - ROC

Evaluation of the individual models based on the **training data**
Confusion Matrix:
+-----------------+---------------+---------------+
|     Metric      | Treated Group | Control Group |
+-----------------+---------------+---------------+
| True Positives  |     3708      |     3625      |
| False Positives |      128      |      110      |
| False Negatives |      382      |      398      |
| True Negatives  |      397      |      372      |
+-----------------+---------------+---------------+

Metrics:
+-----------+---------------+---------------+
|  Metric   | Treated Group | Control Group |
+-----------+---------------+---------------+
| Accuracy  |     0.89      |     0.89      |
| Precision |     0.76      |     0.77      |
|  Recall   |     0.51      |     0.48      |
|    F1     |     0.61      |     0.59      |
|    AUC    |     0.74      |     0.73      |
+-----------+---------------+---------------+


Evaluation of the individual models based on the **test data**
Confusion Matrix:
+-----------------+---------------+---------------+
|     Metric      | Treated Group | Control Group |
+-----------------+---------------+---------------+
| True Positives  |      942      |      893      |
| False Positives |      41       |      30       |
| False Negatives |      85       |      106      |
| True Negatives  |      83       |      100      |
+-----------------+---------------+---------------+

Metrics:
+-----------+---------------+---------------+
|  Metric   | Treated Group | Control Group |
+-----------+---------------+---------------+
| Accuracy  |     0.89      |     0.88      |
| Precision |     0.67      |     0.77      |
|  Recall   |     0.49      |     0.49      |
|    F1     |     0.57      |      0.6      |
|    AUC    |     0.73      |     0.73      |
+-----------+---------------+---------------+

Chapter 4: Evaluate overall ITE Model: Performance 

# This section evaluates the overal performance of the ITE model.
The used performance measures are: 

 - Root Mean Squared Error (RMSE) of the ITE 
 - Accurate estimate of the ATE 
 - Accurancy of ITE


Root Mean Squared Error (RMSE) between the ite and ite_prob: 0.3302

The Actual Average Treatment Effect (ATE): -0.0096
The Predicted Average Treatment Effect (ATE): -0.0132
Accuracy of Average Treatment Effect (ATE): 0.0035


CHAPTER 7: EVALUATE OVERALL ITE MODEL: COST 

# This section evaluates the overal misclassification costs of the ITE model.
We make the matrix: Lost Cause, Sleeping Dog, Persuadable, Sure Thing 
Comment: 
 - Upper left cell: amount of cases that have outcome 0: no matter if you would treat or not 
   If treat, they stay alive, if no treat they also stay alive. 
 - Under right cell: amount of cases that have outcome 1: no matter if you would treat or not 
   If treat, they die, if no treat they also die. 
 - Upper right cell: amount of cases that have outcome 1 if treated, but outcome 0 if not treated 
   If treat, they die, if no treat they stay alive. 
 - Under left cell: amount of cases that have outcome 0 if treated, but outcome 1 if not treated 
   If treat, they stay alive, if no treat they die. 


Crosstab for y_t0 and y_t1:
┌────────┬───────┬───────┐
│   y_t0 │   0.0 │   1.0 │
├────────┼───────┼───────┤
│      0 │  1772 │   112 │
├────────┼───────┼───────┤
│      1 │   134 │   262 │
└────────┴───────┴───────┘

Crosstab for y_t0_pred and y_t1_pred:
┌─────────────┬───────┬───────┐
│   y_t0_pred │   0.0 │   1.0 │
├─────────────┼───────┼───────┤
│           0 │  2008 │     3 │
├─────────────┼───────┼───────┤
│           1 │    33 │   236 │
└─────────────┴───────┴───────┘

Total Misclassification Cost: 2245

CHAPTER 7: REJECTION 

# This section executes and reports metrics for ITE models with rejection.
# Every indicated change are in comparision to the base ITE model without rejection.

ARCHITECTURE TYPE 0: NO REJECTION -- BASELINE MODEL
This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┐
│   ite │   -1.0 │   0.0 │   1.0 │
├───────┼────────┼───────┼───────┤
│    -1 │      4 │   130 │     0 │
├───────┼────────┼───────┼───────┤
│     0 │     26 │  2005 │     3 │
├───────┼────────┼───────┼───────┤
│     1 │      3 │   109 │     0 │
└───────┴────────┴───────┴───────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.12      0.03      0.05       134
           0       0.89      0.99      0.94      2034
           1       0.00      0.00      0.00       112

    accuracy                           0.88      2280
   macro avg       0.34      0.34      0.33      2280
weighted avg       0.80      0.88      0.84      2280

Accuracy: 0.9208
Rejection Rate: 0.0000
Micro TPR: 0.8811
Micro FPR: 0.0594
Macro TPR: 0.3385
Macro FPR: 0.3288


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1329
Macro Distance (3D ROC): 0.7387
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┐
│   ite │   -1.0 │   0.0 │   1.0 │
├───────┼────────┼───────┼───────┤
│    -1 │      4 │   130 │     0 │
├───────┼────────┼───────┼───────┤
│     0 │     26 │  2005 │     3 │
├───────┼────────┼───────┼───────┤
│     1 │      3 │   109 │     0 │
└───────┴────────┴───────┴───────┘
The count of True Accepted is: 2009
The count of False Accepted is: 271
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8811
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8811
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8811

This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┐
│   ite │   -1.0 │   0.0 │   1.0 │
├───────┼────────┼───────┼───────┤
│    -1 │      4 │   130 │     0 │
├───────┼────────┼───────┼───────┤
│     0 │     26 │  2005 │     3 │
├───────┼────────┼───────┼───────┤
│     1 │      3 │   109 │     0 │
└───────┴────────┴───────┴───────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.12      0.03      0.05       134
           0       0.89      0.99      0.94      2034
           1       0.00      0.00      0.00       112

    accuracy                           0.88      2280
   macro avg       0.34      0.34      0.33      2280
weighted avg       0.80      0.88      0.84      2280

Accuracy: 0.9208
Rejection Rate: 0.0000
Micro TPR: 0.8811
Micro FPR: 0.0594
Macro TPR: 0.3385
Macro FPR: 0.3288


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1329
Macro Distance (3D ROC): 0.7387
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┐
│   ite │   -1.0 │   0.0 │   1.0 │
├───────┼────────┼───────┼───────┤
│    -1 │      4 │   130 │     0 │
├───────┼────────┼───────┼───────┤
│     0 │     26 │  2005 │     3 │
├───────┼────────┼───────┼───────┤
│     1 │      3 │   109 │     0 │
└───────┴────────┴───────┴───────┘
The count of True Accepted is: 2009
The count of False Accepted is: 271
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8811
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8811
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8811


Improvements due to a rejection rate of 0.00%:
- Change of the Misclassification Cost: 0.00%
- Change of the ITE Accurancy: 0.00%
- Change of the 3D ROC (micro): 0.00%
- Change of the 3D ROC (macro): 0.00%

ARCHITECTURE TYPE 1: SEPARATED

REJECTION TYPE 1A: OUT OF DISRIBUTION
This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      3 │   112 │     0 │  19 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │     22 │  1676 │     1 │ 335 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │    87 │     0 │  23 │
└───────┴────────┴───────┴───────┴─────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.11      0.03      0.04       115
           0       0.89      0.99      0.94      1699
           1       0.00      0.00      0.00        89

    accuracy                           0.88      1903
   macro avg       0.33      0.34      0.33      1903
weighted avg       0.80      0.88      0.84      1903

Accuracy: 0.9215
Rejection Rate: 0.1654
Micro TPR: 0.8823
Micro FPR: 0.0589
Macro TPR: 0.3375
Macro FPR: 0.3298


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.2113
Macro Distance (3D ROC): 0.7583
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      3 │   112 │     0 │  19 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │     22 │  1676 │     1 │ 335 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │    87 │     0 │  23 │
└───────┴────────┴───────┴───────┴─────┘
The count of True Accepted is: 1679
The count of False Accepted is: 224
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8823
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8823
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8823

This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      3 │   112 │     0 │  19 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │     22 │  1676 │     1 │ 335 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │    87 │     0 │  23 │
└───────┴────────┴───────┴───────┴─────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.11      0.03      0.04       115
           0       0.89      0.99      0.94      1699
           1       0.00      0.00      0.00        89

    accuracy                           0.88      1903
   macro avg       0.33      0.34      0.33      1903
weighted avg       0.80      0.88      0.84      1903

Accuracy: 0.9215
Rejection Rate: 0.1654
Micro TPR: 0.8823
Micro FPR: 0.0589
Macro TPR: 0.3375
Macro FPR: 0.3298


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.2113
Macro Distance (3D ROC): 0.7583
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      3 │   112 │     0 │  19 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │     22 │  1676 │     1 │ 335 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │    87 │     0 │  23 │
└───────┴────────┴───────┴───────┴─────┘
The count of True Accepted is: 1679
The count of False Accepted is: 224
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8823
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8823
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8823


Improvements due to a rejection rate of 16.54%:
- Change of the Misclassification Cost: 13.95%
- Change of the ITE Accurancy: 0.08%
- Change of the 3D ROC (micro): 37.12%
- Change of the 3D ROC (macro): 2.59%

REJECTION TYPE 1B: ONE CLASS CLASSIFICATION MODEL using OCSVM

The best threshold is 0.20100659337361054
This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┬──────┐
│   ite │   -1.0 │   0.0 │   1.0 │    R │
├───────┼────────┼───────┼───────┼──────┤
│    -1 │      2 │    67 │     0 │   65 │
├───────┼────────┼───────┼───────┼──────┤
│     0 │     12 │   984 │     1 │ 1037 │
├───────┼────────┼───────┼───────┼──────┤
│     1 │      1 │    48 │     0 │   63 │
└───────┴────────┴───────┴───────┴──────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.13      0.03      0.05        69
           0       0.90      0.99      0.94       997
           1       0.00      0.00      0.00        49

    accuracy                           0.88      1115
   macro avg       0.34      0.34      0.33      1115
weighted avg       0.81      0.88      0.84      1115

Accuracy: 0.9229
Rejection Rate: 0.5110
Micro TPR: 0.8843
Micro FPR: 0.0578
Macro TPR: 0.3386
Macro FPR: 0.3293


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.5271
Macro Distance (3D ROC): 0.8983
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┬──────┐
│   ite │   -1.0 │   0.0 │   1.0 │    R │
├───────┼────────┼───────┼───────┼──────┤
│    -1 │      2 │    67 │     0 │   65 │
├───────┼────────┼───────┼───────┼──────┤
│     0 │     12 │   984 │     1 │ 1037 │
├───────┼────────┼───────┼───────┼──────┤
│     1 │      1 │    48 │     0 │   63 │
└───────┴────────┴───────┴───────┴──────┘
The count of True Accepted is: 986
The count of False Accepted is: 129
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8843
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8843
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8843

This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┬──────┐
│   ite │   -1.0 │   0.0 │   1.0 │    R │
├───────┼────────┼───────┼───────┼──────┤
│    -1 │      2 │    67 │     0 │   65 │
├───────┼────────┼───────┼───────┼──────┤
│     0 │     12 │   984 │     1 │ 1037 │
├───────┼────────┼───────┼───────┼──────┤
│     1 │      1 │    48 │     0 │   63 │
└───────┴────────┴───────┴───────┴──────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.13      0.03      0.05        69
           0       0.90      0.99      0.94       997
           1       0.00      0.00      0.00        49

    accuracy                           0.88      1115
   macro avg       0.34      0.34      0.33      1115
weighted avg       0.81      0.88      0.84      1115

Accuracy: 0.9229
Rejection Rate: 0.5110
Micro TPR: 0.8843
Micro FPR: 0.0578
Macro TPR: 0.3386
Macro FPR: 0.3293


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.5271
Macro Distance (3D ROC): 0.8983
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┬──────┐
│   ite │   -1.0 │   0.0 │   1.0 │    R │
├───────┼────────┼───────┼───────┼──────┤
│    -1 │      2 │    67 │     0 │   65 │
├───────┼────────┼───────┼───────┼──────┤
│     0 │     12 │   984 │     1 │ 1037 │
├───────┼────────┼───────┼───────┼──────┤
│     1 │      1 │    48 │     0 │   63 │
└───────┴────────┴───────┴───────┴──────┘
The count of True Accepted is: 986
The count of False Accepted is: 129
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8843
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8843
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8843


Improvements due to a rejection rate of 51.10%:
- Change of the Misclassification Cost: 34.83%
- Change of the ITE Accurancy: 0.23%
- Change of the 3D ROC (micro): 74.79%
- Change of the 3D ROC (macro): 17.77%

REJECTION TYPE 1C: SCORE MODEL

 - Not done yet
This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┐
│   ite │   -1.0 │   0.0 │   1.0 │
├───────┼────────┼───────┼───────┤
│    -1 │      4 │   130 │     0 │
├───────┼────────┼───────┼───────┤
│     0 │     26 │  2005 │     3 │
├───────┼────────┼───────┼───────┤
│     1 │      3 │   109 │     0 │
└───────┴────────┴───────┴───────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.12      0.03      0.05       134
           0       0.89      0.99      0.94      2034
           1       0.00      0.00      0.00       112

    accuracy                           0.88      2280
   macro avg       0.34      0.34      0.33      2280
weighted avg       0.80      0.88      0.84      2280

Accuracy: 0.9208
Rejection Rate: 0.0000
Micro TPR: 0.8811
Micro FPR: 0.0594
Macro TPR: 0.3385
Macro FPR: 0.3288


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1329
Macro Distance (3D ROC): 0.7387
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┐
│   ite │   -1.0 │   0.0 │   1.0 │
├───────┼────────┼───────┼───────┤
│    -1 │      4 │   130 │     0 │
├───────┼────────┼───────┼───────┤
│     0 │     26 │  2005 │     3 │
├───────┼────────┼───────┼───────┤
│     1 │      3 │   109 │     0 │
└───────┴────────┴───────┴───────┘
The count of True Accepted is: 2009
The count of False Accepted is: 271
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8811
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8811
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8811

This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┐
│   ite │   -1.0 │   0.0 │   1.0 │
├───────┼────────┼───────┼───────┤
│    -1 │      4 │   130 │     0 │
├───────┼────────┼───────┼───────┤
│     0 │     26 │  2005 │     3 │
├───────┼────────┼───────┼───────┤
│     1 │      3 │   109 │     0 │
└───────┴────────┴───────┴───────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.12      0.03      0.05       134
           0       0.89      0.99      0.94      2034
           1       0.00      0.00      0.00       112

    accuracy                           0.88      2280
   macro avg       0.34      0.34      0.33      2280
weighted avg       0.80      0.88      0.84      2280

Accuracy: 0.9208
Rejection Rate: 0.0000
Micro TPR: 0.8811
Micro FPR: 0.0594
Macro TPR: 0.3385
Macro FPR: 0.3288


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1329
Macro Distance (3D ROC): 0.7387
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┐
│   ite │   -1.0 │   0.0 │   1.0 │
├───────┼────────┼───────┼───────┤
│    -1 │      4 │   130 │     0 │
├───────┼────────┼───────┼───────┤
│     0 │     26 │  2005 │     3 │
├───────┼────────┼───────┼───────┤
│     1 │      3 │   109 │     0 │
└───────┴────────┴───────┴───────┘
The count of True Accepted is: 2009
The count of False Accepted is: 271
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8811
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8811
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8811


Improvements due to a rejection rate of 0.00%:
- Change of the Misclassification Cost: 0.00%
- Change of the ITE Accurancy: 0.00%
- Change of the 3D ROC (micro): 0.00%
- Change of the 3D ROC (macro): 0.00%

ARCHITECTURE TYPE 2: DEPENDENT

REJECTION TYPE 2A: REJECTION BASED ON PROBABILITIES BY MINIMIZING 3DROC 

VARIANT TYPE 2A I: OPTIMIZATION OF SINGLE BOUNDARIES BY MINIMIZING 3DROC 

ITE values witht a probability between the optimal underbound 0.4133913360727779 and the optimal upperbound 0.5866086639272221 are rejected This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      3 │   120 │     0 │  11 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │      9 │  1955 │     2 │  68 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │    99 │     0 │  11 │
└───────┴────────┴───────┴───────┴─────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.21      0.02      0.04       123
           0       0.90      0.99      0.94      1966
           1       0.00      0.00      0.00       101

    accuracy                           0.89      2190
   macro avg       0.37      0.34      0.33      2190
weighted avg       0.82      0.89      0.85      2190

Accuracy: 0.9294
Rejection Rate: 0.0395
Micro TPR: 0.8941
Micro FPR: 0.0530
Macro TPR: 0.3396
Macro FPR: 0.3280


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1248
Macro Distance (3D ROC): 0.7384
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      3 │   120 │     0 │  11 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │      9 │  1955 │     2 │  68 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │    99 │     0 │  11 │
└───────┴────────┴───────┴───────┴─────┘
The count of True Accepted is: 1958
The count of False Accepted is: 232
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8941
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8941
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8941

This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      3 │   120 │     0 │  11 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │      9 │  1955 │     2 │  68 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │    99 │     0 │  11 │
└───────┴────────┴───────┴───────┴─────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.21      0.02      0.04       123
           0       0.90      0.99      0.94      1966
           1       0.00      0.00      0.00       101

    accuracy                           0.89      2190
   macro avg       0.37      0.34      0.33      2190
weighted avg       0.82      0.89      0.85      2190

Accuracy: 0.9294
Rejection Rate: 0.0395
Micro TPR: 0.8941
Micro FPR: 0.0530
Macro TPR: 0.3396
Macro FPR: 0.3280


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1248
Macro Distance (3D ROC): 0.7384
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      3 │   120 │     0 │  11 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │      9 │  1955 │     2 │  68 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │    99 │     0 │  11 │
└───────┴────────┴───────┴───────┴─────┘
The count of True Accepted is: 1958
The count of False Accepted is: 232
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8941
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8941
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8941


Improvements due to a rejection rate of 3.95%:
- Change of the Misclassification Cost: 1.10%
- Change of the ITE Accurancy: 0.93%
- Change of the 3D ROC (micro): -6.44%
- Change of the 3D ROC (macro): -0.04%

VARIANT TYPE 2A II: OPTIMIZATION OF DOUBLE BOUNDARIES BY MINIMIZING 3DROC  

ITE values witht a probability between the optimal underbound 0.45 and the optimal upperbound 0.55 are rejected This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      3 │   127 │     0 │   4 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │     15 │  1979 │     3 │  37 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │   106 │     0 │   4 │
└───────┴────────┴───────┴───────┴─────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.15      0.02      0.04       130
           0       0.89      0.99      0.94      1997
           1       0.00      0.00      0.00       108

    accuracy                           0.89      2235
   macro avg       0.35      0.34      0.33      2235
weighted avg       0.81      0.89      0.84      2235

Accuracy: 0.9245
Rejection Rate: 0.0197
Micro TPR: 0.8868
Micro FPR: 0.0566
Macro TPR: 0.3380
Macro FPR: 0.3295


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1281
Macro Distance (3D ROC): 0.7397
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      3 │   127 │     0 │   4 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │     15 │  1979 │     3 │  37 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │   106 │     0 │   4 │
└───────┴────────┴───────┴───────┴─────┘
The count of True Accepted is: 1982
The count of False Accepted is: 253
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8868
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8868
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8868

This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      3 │   127 │     0 │   4 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │     15 │  1979 │     3 │  37 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │   106 │     0 │   4 │
└───────┴────────┴───────┴───────┴─────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.15      0.02      0.04       130
           0       0.89      0.99      0.94      1997
           1       0.00      0.00      0.00       108

    accuracy                           0.89      2235
   macro avg       0.35      0.34      0.33      2235
weighted avg       0.81      0.89      0.84      2235

Accuracy: 0.9245
Rejection Rate: 0.0197
Micro TPR: 0.8868
Micro FPR: 0.0566
Macro TPR: 0.3380
Macro FPR: 0.3295


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1281
Macro Distance (3D ROC): 0.7397
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      3 │   127 │     0 │   4 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │     15 │  1979 │     3 │  37 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │   106 │     0 │   4 │
└───────┴────────┴───────┴───────┴─────┘
The count of True Accepted is: 1982
The count of False Accepted is: 253
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8868
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8868
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8868


Improvements due to a rejection rate of 1.97%:
- Change of the Misclassification Cost: 2.18%
- Change of the ITE Accurancy: 0.41%
- Change of the 3D ROC (micro): -3.75%
- Change of the 3D ROC (macro): 0.14%

REJECTION TYPE 2A: REJECTION BASED ON PROBABILITIES BY MINIMIZING MISCLASSIFICATION COSTS 

ITE values witht a probability between the optimal underbound 0.2547447183904272 and the optimal upperbound 0.7452552816095728 are rejected This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   R │
├───────┼────────┼───────┼─────┤
│    -1 │      0 │    92 │  42 │
├───────┼────────┼───────┼─────┤
│     0 │      1 │  1764 │ 269 │
├───────┼────────┼───────┼─────┤
│     1 │      0 │    62 │  50 │
└───────┴────────┴───────┴─────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.00      0.00      0.00        92
           0       0.92      1.00      0.96      1765
           1       0.00      0.00      0.00        62

    accuracy                           0.92      1919
   macro avg       0.31      0.33      0.32      1919
weighted avg       0.85      0.92      0.88      1919

Accuracy: 0.9462
Rejection Rate: 0.1583
Micro TPR: 0.9192
Micro FPR: 0.0404
Macro TPR: 0.3331
Macro FPR: 0.3335


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1823
Macro Distance (3D ROC): 0.7622
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   R │
├───────┼────────┼───────┼─────┤
│    -1 │      0 │    92 │  42 │
├───────┼────────┼───────┼─────┤
│     0 │      1 │  1764 │ 269 │
├───────┼────────┼───────┼─────┤
│     1 │      0 │    62 │  50 │
└───────┴────────┴───────┴─────┘
The count of True Accepted is: 1764
The count of False Accepted is: 155
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.9192
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.9192
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.9192

This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   R │
├───────┼────────┼───────┼─────┤
│    -1 │      0 │    92 │  42 │
├───────┼────────┼───────┼─────┤
│     0 │      1 │  1764 │ 269 │
├───────┼────────┼───────┼─────┤
│     1 │      0 │    62 │  50 │
└───────┴────────┴───────┴─────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.00      0.00      0.00        92
           0       0.92      1.00      0.96      1765
           1       0.00      0.00      0.00        62

    accuracy                           0.92      1919
   macro avg       0.31      0.33      0.32      1919
weighted avg       0.85      0.92      0.88      1919

Accuracy: 0.9462
Rejection Rate: 0.1583
Micro TPR: 0.9192
Micro FPR: 0.0404
Macro TPR: 0.3331
Macro FPR: 0.3335


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1823
Macro Distance (3D ROC): 0.7622
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   R │
├───────┼────────┼───────┼─────┤
│    -1 │      0 │    92 │  42 │
├───────┼────────┼───────┼─────┤
│     0 │      1 │  1764 │ 269 │
├───────┼────────┼───────┼─────┤
│     1 │      0 │    62 │  50 │
└───────┴────────┴───────┴─────┘
The count of True Accepted is: 1764
The count of False Accepted is: 155
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.9192
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.9192
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.9192


Improvements due to a rejection rate of 15.83%:
- Change of the Misclassification Cost: -1.95%
- Change of the ITE Accurancy: 2.68%
- Change of the 3D ROC (micro): 27.09%
- Change of the 3D ROC (macro): 3.09%


Table of test_set (First 20 rows)
+-----------+-----------+-----------+-----------+-----------+----------+----------+------+------+------+--------------+---------------+----------+------------+-----------------+-------+------------------+------------------+---------------+----------+
| treatment | y_t1_pred | y_t1_prob | y_t0_pred | y_t0_prob | ite_pred | ite_prob | y_t0 | y_t1 | ite  |   category   | category_pred | cost_ite | ite_reject | cost_ite_reject |  ood  | y_t1_reject_prob | y_t0_reject_prob | y_reject_prob | y_reject |
+-----------+-----------+-----------+-----------+-----------+----------+----------+------+------+------+--------------+---------------+----------+------------+-----------------+-------+------------------+------------------+---------------+----------+
|     0     |    0.0    |  0.0236   |    0.0    |  0.0596   |   0.0    |  -0.036  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.0228   |    0.0    |  0.0701   |   0.0    | -0.0473  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.1384   |    0.0    |  0.1524   |   0.0    |  -0.014  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | True  |      False       |      False       |     False     |  False   |
|     1     |    1.0    |  0.6277   |    1.0    |  0.7077   |   0.0    | -0.0799  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Sure Thing   |    0     |     R      |        2        | True  |       True       |       True       |     True      |   True   |
|     0     |    0.0    |  0.3436   |    0.0    |  0.3937   |   0.0    | -0.0501  | 1.0  | 0.0  | -1.0 | Sleeping Dog |  Lost Cause   |    10    |     R      |        2        | False |       True       |       True       |     True      |   True   |
|     0     |    1.0    |  0.5144   |    1.0    |  0.5628   |   0.0    | -0.0484  | 1.0  | 1.0  | 0.0  |  Sure Thing  |  Sure Thing   |    0     |     R      |        2        | False |       True       |       True       |     True      |   True   |
|     1     |    0.0    |  0.0081   |    0.0    |  0.0141   |   0.0    |  -0.006  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | True  |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.1716   |    0.0    |   0.156   |   0.0    |  0.0156  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | True  |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.1194   |    0.0    |  0.1456   |   0.0    | -0.0263  | 0.0  | 1.0  | 1.0  | Persuadable  |  Lost Cause   |    10    |    0.0     |       10        | False |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.1373   |    0.0    |  0.1767   |   0.0    | -0.0394  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | True  |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.0467   |    0.0    |  0.0659   |   0.0    | -0.0192  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.1165   |    0.0    |  0.1808   |   0.0    | -0.0644  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.0075   |    0.0    |   0.015   |   0.0    | -0.0074  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.0296   |    0.0    |  0.0457   |   0.0    | -0.0161  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.0285   |    0.0    |  0.0512   |   0.0    | -0.0227  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | True  |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.0141   |    0.0    |  0.0222   |   0.0    | -0.0082  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     0     |    1.0    |  0.5868   |    1.0    |  0.7008   |   0.0    |  -0.114  | 1.0  | 0.0  | -1.0 | Sleeping Dog |  Sure Thing   |    0     |     R      |        2        | False |       True       |       True       |     True      |   True   |
|     0     |    0.0    |  0.0052   |    0.0    |  0.0098   |   0.0    | -0.0046  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | True  |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.0142   |    0.0    |  0.0306   |   0.0    | -0.0164  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     1     |    1.0    |  0.9217   |    1.0    |  0.9267   |   0.0    |  -0.005  | 1.0  | 0.0  | -1.0 | Sleeping Dog |  Sure Thing   |    0     |    0.0     |        0        | True  |      False       |      False       |     False     |  False   |
+-----------+-----------+-----------+-----------+-----------+----------+----------+------+------+------+--------------+---------------+----------+------------+-----------------+-------+------------------+------------------+---------------+----------+

Table of results of the experiments
╭──────────────┬─────────────────────┬───────────────────────┬────────────┬──────────────────┬─────────────┬─────────────┬─────────────┬─────────────╮
│   Experiment │ Architecture Type   │ Rejection Type        │   Accuracy │   Rejection Rate │   Micro TPR │   Micro FPR │   Macro TPR │   Macro FPR │
├──────────────┼─────────────────────┼───────────────────────┼────────────┼──────────────────┼─────────────┼─────────────┼─────────────┼─────────────┤
│            0 │ No Rejection        │ No Rejection          │     0.9208 │           0      │      0.8811 │      0.0594 │      0.3385 │      0.3288 │
├──────────────┼─────────────────────┼───────────────────────┼────────────┼──────────────────┼─────────────┼─────────────┼─────────────┼─────────────┤
│            1 │ separated           │ OOD - KNN             │     0.9215 │           0.1654 │      0.8823 │      0.0589 │      0.3375 │      0.3298 │
├──────────────┼─────────────────────┼───────────────────────┼────────────┼──────────────────┼─────────────┼─────────────┼─────────────┼─────────────┤
│            2 │ separated           │ OCSVM                 │     0.9229 │           0.511  │      0.8843 │      0.0578 │      0.3386 │      0.3293 │
├──────────────┼─────────────────────┼───────────────────────┼────────────┼──────────────────┼─────────────┼─────────────┼─────────────┼─────────────┤
│            3 │ separated           │ Scores Model          │     0.9208 │           0      │      0.8811 │      0.0594 │      0.3385 │      0.3288 │
├──────────────┼─────────────────────┼───────────────────────┼────────────┼──────────────────┼─────────────┼─────────────┼─────────────┼─────────────┤
│            4 │ dependent           │ prob symetric bounds  │     0.9294 │           0.0395 │      0.8941 │      0.053  │      0.3396 │      0.328  │
├──────────────┼─────────────────────┼───────────────────────┼────────────┼──────────────────┼─────────────┼─────────────┼─────────────┼─────────────┤
│            5 │ dependent           │ prob asymetric bounds │     0.9245 │           0.0197 │      0.8868 │      0.0566 │      0.338  │      0.3295 │
├──────────────┼─────────────────────┼───────────────────────┼────────────┼──────────────────┼─────────────┼─────────────┼─────────────┼─────────────┤
│            6 │ dependent           │ prob miscost          │     0.9462 │           0.1583 │      0.9192 │      0.0404 │      0.3331 │      0.3335 │
╰──────────────┴─────────────────────┴───────────────────────┴────────────┴──────────────────┴─────────────┴─────────────┴─────────────┴─────────────╯

Table of results of the experiments

╭───────────────────┬──────────────┬───────────┬───────────┬──────────────┬──────────────────────┬───────────────────────┬──────────────╮
│ Experiment        │ 0            │ 1         │ 2         │ 3            │ 4                    │ 5                     │ 6            │
├───────────────────┼──────────────┼───────────┼───────────┼──────────────┼──────────────────────┼───────────────────────┼──────────────┤
│ Architecture Type │ No Rejection │ separated │ separated │ separated    │ dependent            │ dependent             │ dependent    │
├───────────────────┼──────────────┼───────────┼───────────┼──────────────┼──────────────────────┼───────────────────────┼──────────────┤
│ Rejection Type    │ No Rejection │ OOD - KNN │ OCSVM     │ Scores Model │ prob symetric bounds │ prob asymetric bounds │ prob miscost │
├───────────────────┼──────────────┼───────────┼───────────┼──────────────┼──────────────────────┼───────────────────────┼──────────────┤
│ Accuracy          │ 0.9208       │ 0.9215    │ 0.9229    │ 0.9208       │ 0.9294               │ 0.9245                │ 0.9462       │
├───────────────────┼──────────────┼───────────┼───────────┼──────────────┼──────────────────────┼───────────────────────┼──────────────┤
│ Rejection Rate    │ 0.0          │ 0.1654    │ 0.511     │ 0.0          │ 0.0395               │ 0.0197                │ 0.1583       │
├───────────────────┼──────────────┼───────────┼───────────┼──────────────┼──────────────────────┼───────────────────────┼──────────────┤
│ Micro TPR         │ 0.8811       │ 0.8823    │ 0.8843    │ 0.8811       │ 0.8941               │ 0.8868                │ 0.9192       │
├───────────────────┼──────────────┼───────────┼───────────┼──────────────┼──────────────────────┼───────────────────────┼──────────────┤
│ Micro FPR         │ 0.0594       │ 0.0589    │ 0.0578    │ 0.0594       │ 0.053                │ 0.0566                │ 0.0404       │
├───────────────────┼──────────────┼───────────┼───────────┼──────────────┼──────────────────────┼───────────────────────┼──────────────┤
│ Macro TPR         │ 0.3385       │ 0.3375    │ 0.3386    │ 0.3385       │ 0.3396               │ 0.338                 │ 0.3331       │
├───────────────────┼──────────────┼───────────┼───────────┼──────────────┼──────────────────────┼───────────────────────┼──────────────┤
│ Macro FPR         │ 0.3288       │ 0.3298    │ 0.3293    │ 0.3288       │ 0.328                │ 0.3295                │ 0.3335       │
╰───────────────────┴──────────────┴───────────┴───────────┴──────────────┴──────────────────────┴───────────────────────┴──────────────╯