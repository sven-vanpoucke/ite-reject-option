CHAPTER 1: INTRODUCTION
# This section introduces the purpose and background of the analysis.

In this analysis, we aim to evaluate the performance of different reject options for Information Treatment Effect (ITE) models.The ITE model predicts the individual treatment effects in a given dataset, providing valuable insights into the impact of interventions.
For your information, this file has been automatically generated on: 2024-02-07 21:30
\Chapter 2: Preprocessing

# This section executes the data retrieval, preprocessing and splitting in a training and dataset.During the whole file, the used dataset is: TWINS

CHAPTER 3: Training of the ITE Model

# This section provides details about the model selection, training process, and any hyperparameter tuning.
The trained ITE model is a T-LEARNER.
The two individually trained models are: LogisticRegression

CHAPTER 4: Evaluate treated and control groups seperately

# This section evaluates the individually trained models (two as we used a T-learner).
The used performance measures are:

 - Confusion Matrix
 - Accuracy: overall correctness of the model ((TP + TN) / (TP + TN + FP + FN))
 - Precision: It measures the accuracy of positive predictions (TP / (TP + FP))
 - Recall: ability of the model to capture all the relevant cases (TP / (TP + FN))
 - F1 Score: It balances precision and recall, providing a single metric for model evaluation (2 * (Precision * Recall) / (Precision + Recall))
 - ROC

Evaluation of the individual models based on the **training data**
Confusion Matrix:
+-----------------+---------------+---------------+
|     Metric      | Treated Group | Control Group |
+-----------------+---------------+---------------+
| True Positives  |     3724      |     3635      |
| False Positives |      123      |      110      |
| False Negatives |      358      |      423      |
| True Negatives  |      387      |      360      |
+-----------------+---------------+---------------+

Metrics:
+-----------+---------------+---------------+
|  Metric   | Treated Group | Control Group |
+-----------+---------------+---------------+
| Accuracy  |      0.9      |     0.88      |
| Precision |     0.76      |     0.77      |
|  Recall   |     0.52      |     0.46      |
|    F1     |     0.62      |     0.57      |
|    AUC    |     0.74      |     0.72      |
+-----------+---------------+---------------+


Evaluation of the individual models based on the **test data**
Confusion Matrix:
+-----------------+---------------+---------------+
|     Metric      | Treated Group | Control Group |
+-----------------+---------------+---------------+
| True Positives  |      922      |      900      |
| False Positives |      30       |      33       |
| False Negatives |      91       |      111      |
| True Negatives  |      93       |      100      |
+-----------------+---------------+---------------+

Metrics:
+-----------+---------------+---------------+
|  Metric   | Treated Group | Control Group |
+-----------+---------------+---------------+
| Accuracy  |     0.89      |     0.87      |
| Precision |     0.76      |     0.75      |
|  Recall   |     0.51      |     0.47      |
|    F1     |     0.61      |     0.58      |
|    AUC    |     0.74      |     0.72      |
+-----------+---------------+---------------+

Chapter 4: Evaluate overall ITE Model: Performance 

# This section evaluates the overal performance of the ITE model.
The used performance measures are: 

 - Root Mean Squared Error (RMSE) of the ITE 
 - Accurate estimate of the ATE 
 - Accurancy of ITE


Root Mean Squared Error (RMSE) between the ite and ite_prob: 0.3287

The Actual Average Treatment Effect (ATE): -0.0022
The Predicted Average Treatment Effect (ATE): -0.0013
Accuracy of Average Treatment Effect (ATE): 0.0009


CHAPTER 7: EVALUATE OVERALL ITE MODEL: COST 

# This section evaluates the overal misclassification costs of the ITE model.
We make the matrix: Lost Cause, Sleeping Dog, Persuadable, Sure Thing 
Comment: 
 - Upper left cell: amount of cases that have outcome 0: no matter if you would treat or not 
   If treat, they stay alive, if no treat they also stay alive. 
 - Under right cell: amount of cases that have outcome 1: no matter if you would treat or not 
   If treat, they die, if no treat they also die. 
 - Upper right cell: amount of cases that have outcome 1 if treated, but outcome 0 if not treated 
   If treat, they die, if no treat they stay alive. 
 - Under left cell: amount of cases that have outcome 0 if treated, but outcome 1 if not treated 
   If treat, they stay alive, if no treat they die. 


Crosstab for y_t0 and y_t1:
┌────────┬───────┬───────┐
│   y_t0 │   0.0 │   1.0 │
├────────┼───────┼───────┤
│      0 │  1774 │   119 │
├────────┼───────┼───────┤
│      1 │   124 │   263 │
└────────┴───────┴───────┘

Crosstab for y_t0_pred and y_t1_pred:
┌─────────────┬───────┬───────┐
│   y_t0_pred │   0.0 │   1.0 │
├─────────────┼───────┼───────┤
│           0 │  2007 │    19 │
├─────────────┼───────┼───────┤
│           1 │    22 │   232 │
└─────────────┴───────┴───────┘

Total Misclassification Cost: 2265

CHAPTER 7: REJECTION 

# This section executes and reports metrics for ITE models with rejection.
# Every indicated change are in comparision to the base ITE model without rejection.

ARCHITECTURE TYPE 0: NO REJECTION -- BASELINE MODEL
This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┐
│   ite │   -1.0 │   0.0 │   1.0 │
├───────┼────────┼───────┼───────┤
│    -1 │      5 │   118 │     1 │
├───────┼────────┼───────┼───────┤
│     0 │     14 │  2009 │    14 │
├───────┼────────┼───────┼───────┤
│     1 │      3 │   112 │     4 │
└───────┴────────┴───────┴───────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.23      0.04      0.07       124
           0       0.90      0.99      0.94      2037
           1       0.21      0.03      0.06       119

    accuracy                           0.89      2280
   macro avg       0.45      0.35      0.36      2280
weighted avg       0.82      0.89      0.85      2280

Accuracy: 0.9234
Rejection Rate: 0.0000
Micro TPR: 0.8851
Micro FPR: 0.0575
Macro TPR: 0.3534
Macro FPR: 0.3204


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1285
Macro Distance (3D ROC): 0.7217
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┐
│   ite │   -1.0 │   0.0 │   1.0 │
├───────┼────────┼───────┼───────┤
│    -1 │      5 │   118 │     1 │
├───────┼────────┼───────┼───────┤
│     0 │     14 │  2009 │    14 │
├───────┼────────┼───────┼───────┤
│     1 │      3 │   112 │     4 │
└───────┴────────┴───────┴───────┘
The count of True Accepted is: 2018
The count of False Accepted is: 262
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8851
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8851
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8851

This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┐
│   ite │   -1.0 │   0.0 │   1.0 │
├───────┼────────┼───────┼───────┤
│    -1 │      5 │   118 │     1 │
├───────┼────────┼───────┼───────┤
│     0 │     14 │  2009 │    14 │
├───────┼────────┼───────┼───────┤
│     1 │      3 │   112 │     4 │
└───────┴────────┴───────┴───────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.23      0.04      0.07       124
           0       0.90      0.99      0.94      2037
           1       0.21      0.03      0.06       119

    accuracy                           0.89      2280
   macro avg       0.45      0.35      0.36      2280
weighted avg       0.82      0.89      0.85      2280

Accuracy: 0.9234
Rejection Rate: 0.0000
Micro TPR: 0.8851
Micro FPR: 0.0575
Macro TPR: 0.3534
Macro FPR: 0.3204


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1285
Macro Distance (3D ROC): 0.7217
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┐
│   ite │   -1.0 │   0.0 │   1.0 │
├───────┼────────┼───────┼───────┤
│    -1 │      5 │   118 │     1 │
├───────┼────────┼───────┼───────┤
│     0 │     14 │  2009 │    14 │
├───────┼────────┼───────┼───────┤
│     1 │      3 │   112 │     4 │
└───────┴────────┴───────┴───────┘
The count of True Accepted is: 2018
The count of False Accepted is: 262
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8851
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8851
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8851


Improvements due to a rejection rate of 0.00%:
- Change of the Misclassification Cost: 0.00%
- Change of the ITE Accurancy: 0.00%
- Change of the 3D ROC (micro): 0.00%
- Change of the 3D ROC (macro): 0.00%

ARCHITECTURE TYPE 1: SEPARATED

REJECTION TYPE 1A: OUT OF DISRIBUTION
This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      4 │    93 │     1 │  26 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │     10 │  1684 │    11 │ 332 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │    95 │     4 │  18 │
└───────┴────────┴───────┴───────┴─────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.25      0.04      0.07        98
           0       0.90      0.99      0.94      1705
           1       0.25      0.04      0.07       101

    accuracy                           0.89      1904
   macro avg       0.47      0.36      0.36      1904
weighted avg       0.83      0.89      0.85      1904

Accuracy: 0.9258
Rejection Rate: 0.1649
Micro TPR: 0.8887
Micro FPR: 0.0557
Macro TPR: 0.3560
Macro FPR: 0.3193


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.2066
Macro Distance (3D ROC): 0.7375
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      4 │    93 │     1 │  26 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │     10 │  1684 │    11 │ 332 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │    95 │     4 │  18 │
└───────┴────────┴───────┴───────┴─────┘
The count of True Accepted is: 1692
The count of False Accepted is: 212
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8887
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8887
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8887

This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      4 │    93 │     1 │  26 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │     10 │  1684 │    11 │ 332 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │    95 │     4 │  18 │
└───────┴────────┴───────┴───────┴─────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.25      0.04      0.07        98
           0       0.90      0.99      0.94      1705
           1       0.25      0.04      0.07       101

    accuracy                           0.89      1904
   macro avg       0.47      0.36      0.36      1904
weighted avg       0.83      0.89      0.85      1904

Accuracy: 0.9258
Rejection Rate: 0.1649
Micro TPR: 0.8887
Micro FPR: 0.0557
Macro TPR: 0.3560
Macro FPR: 0.3193


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.2066
Macro Distance (3D ROC): 0.7375
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      4 │    93 │     1 │  26 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │     10 │  1684 │    11 │ 332 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │    95 │     4 │  18 │
└───────┴────────┴───────┴───────┴─────┘
The count of True Accepted is: 1692
The count of False Accepted is: 212
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8887
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8887
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8887


Improvements due to a rejection rate of 16.49%:
- Change of the Misclassification Cost: 12.62%
- Change of the ITE Accurancy: 0.26%
- Change of the 3D ROC (micro): 37.82%
- Change of the 3D ROC (macro): 2.15%

REJECTION TYPE 1B: ONE CLASS CLASSIFICATION MODEL using OCSVM

The best threshold is 0.8782794368191538
This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┬──────┐
│   ite │   -1.0 │   0.0 │   1.0 │    R │
├───────┼────────┼───────┼───────┼──────┤
│    -1 │      3 │    56 │     0 │   65 │
├───────┼────────┼───────┼───────┼──────┤
│     0 │      4 │   986 │     3 │ 1044 │
├───────┼────────┼───────┼───────┼──────┤
│     1 │      1 │    59 │     3 │   56 │
└───────┴────────┴───────┴───────┴──────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.38      0.05      0.09        59
           0       0.90      0.99      0.94       993
           1       0.50      0.05      0.09        63

    accuracy                           0.89      1115
   macro avg       0.59      0.36      0.37      1115
weighted avg       0.85      0.89      0.85      1115

Accuracy: 0.9265
Rejection Rate: 0.5110
Micro TPR: 0.8897
Micro FPR: 0.0552
Macro TPR: 0.3638
Macro FPR: 0.3167


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.5256
Macro Distance (3D ROC): 0.8753
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┬──────┐
│   ite │   -1.0 │   0.0 │   1.0 │    R │
├───────┼────────┼───────┼───────┼──────┤
│    -1 │      3 │    56 │     0 │   65 │
├───────┼────────┼───────┼───────┼──────┤
│     0 │      4 │   986 │     3 │ 1044 │
├───────┼────────┼───────┼───────┼──────┤
│     1 │      1 │    59 │     3 │   56 │
└───────┴────────┴───────┴───────┴──────┘
The count of True Accepted is: 992
The count of False Accepted is: 123
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8897
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8897
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8897

This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┬──────┐
│   ite │   -1.0 │   0.0 │   1.0 │    R │
├───────┼────────┼───────┼───────┼──────┤
│    -1 │      3 │    56 │     0 │   65 │
├───────┼────────┼───────┼───────┼──────┤
│     0 │      4 │   986 │     3 │ 1044 │
├───────┼────────┼───────┼───────┼──────┤
│     1 │      1 │    59 │     3 │   56 │
└───────┴────────┴───────┴───────┴──────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.38      0.05      0.09        59
           0       0.90      0.99      0.94       993
           1       0.50      0.05      0.09        63

    accuracy                           0.89      1115
   macro avg       0.59      0.36      0.37      1115
weighted avg       0.85      0.89      0.85      1115

Accuracy: 0.9265
Rejection Rate: 0.5110
Micro TPR: 0.8897
Micro FPR: 0.0552
Macro TPR: 0.3638
Macro FPR: 0.3167


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.5256
Macro Distance (3D ROC): 0.8753
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┬──────┐
│   ite │   -1.0 │   0.0 │   1.0 │    R │
├───────┼────────┼───────┼───────┼──────┤
│    -1 │      3 │    56 │     0 │   65 │
├───────┼────────┼───────┼───────┼──────┤
│     0 │      4 │   986 │     3 │ 1044 │
├───────┼────────┼───────┼───────┼──────┤
│     1 │      1 │    59 │     3 │   56 │
└───────┴────────┴───────┴───────┴──────┘
The count of True Accepted is: 992
The count of False Accepted is: 123
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8897
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8897
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8897


Improvements due to a rejection rate of 51.10%:
- Change of the Misclassification Cost: 34.25%
- Change of the ITE Accurancy: 0.33%
- Change of the 3D ROC (micro): 75.56%
- Change of the 3D ROC (macro): 17.55%

REJECTION TYPE 1C: SCORE MODEL

 - Not done yet
This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┐
│   ite │   -1.0 │   0.0 │   1.0 │
├───────┼────────┼───────┼───────┤
│    -1 │      5 │   118 │     1 │
├───────┼────────┼───────┼───────┤
│     0 │     14 │  2009 │    14 │
├───────┼────────┼───────┼───────┤
│     1 │      3 │   112 │     4 │
└───────┴────────┴───────┴───────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.23      0.04      0.07       124
           0       0.90      0.99      0.94      2037
           1       0.21      0.03      0.06       119

    accuracy                           0.89      2280
   macro avg       0.45      0.35      0.36      2280
weighted avg       0.82      0.89      0.85      2280

Accuracy: 0.9234
Rejection Rate: 0.0000
Micro TPR: 0.8851
Micro FPR: 0.0575
Macro TPR: 0.3534
Macro FPR: 0.3204


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1285
Macro Distance (3D ROC): 0.7217
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┐
│   ite │   -1.0 │   0.0 │   1.0 │
├───────┼────────┼───────┼───────┤
│    -1 │      5 │   118 │     1 │
├───────┼────────┼───────┼───────┤
│     0 │     14 │  2009 │    14 │
├───────┼────────┼───────┼───────┤
│     1 │      3 │   112 │     4 │
└───────┴────────┴───────┴───────┘
The count of True Accepted is: 2018
The count of False Accepted is: 262
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8851
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8851
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8851

This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┐
│   ite │   -1.0 │   0.0 │   1.0 │
├───────┼────────┼───────┼───────┤
│    -1 │      5 │   118 │     1 │
├───────┼────────┼───────┼───────┤
│     0 │     14 │  2009 │    14 │
├───────┼────────┼───────┼───────┤
│     1 │      3 │   112 │     4 │
└───────┴────────┴───────┴───────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.23      0.04      0.07       124
           0       0.90      0.99      0.94      2037
           1       0.21      0.03      0.06       119

    accuracy                           0.89      2280
   macro avg       0.45      0.35      0.36      2280
weighted avg       0.82      0.89      0.85      2280

Accuracy: 0.9234
Rejection Rate: 0.0000
Micro TPR: 0.8851
Micro FPR: 0.0575
Macro TPR: 0.3534
Macro FPR: 0.3204


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1285
Macro Distance (3D ROC): 0.7217
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┐
│   ite │   -1.0 │   0.0 │   1.0 │
├───────┼────────┼───────┼───────┤
│    -1 │      5 │   118 │     1 │
├───────┼────────┼───────┼───────┤
│     0 │     14 │  2009 │    14 │
├───────┼────────┼───────┼───────┤
│     1 │      3 │   112 │     4 │
└───────┴────────┴───────┴───────┘
The count of True Accepted is: 2018
The count of False Accepted is: 262
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8851
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8851
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8851


Improvements due to a rejection rate of 0.00%:
- Change of the Misclassification Cost: 0.00%
- Change of the ITE Accurancy: 0.00%
- Change of the 3D ROC (micro): 0.00%
- Change of the 3D ROC (macro): 0.00%

ARCHITECTURE TYPE 2: DEPENDENT

REJECTION TYPE 2A: REJECTION BASED ON PROBABILITIES BY MINIMIZING 3DROC 

VARIANT TYPE 2A I: OPTIMIZATION OF SINGLE BOUNDARIES BY MINIMIZING 3DROC 

ITE values witht a probability between the optimal underbound 0.4000739441193548 and the optimal upperbound 0.5999260558806452 are rejected This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      1 │   106 │     0 │  17 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │      5 │  1961 │     3 │  68 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │   104 │     0 │  13 │
└───────┴────────┴───────┴───────┴─────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.12      0.01      0.02       107
           0       0.90      1.00      0.95      1969
           1       0.00      0.00      0.00       106

    accuracy                           0.90      2182
   macro avg       0.34      0.34      0.32      2182
weighted avg       0.82      0.90      0.86      2182

Accuracy: 0.9328
Rejection Rate: 0.0430
Micro TPR: 0.8992
Micro FPR: 0.0504
Macro TPR: 0.3351
Macro FPR: 0.3302


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1206
Macro Distance (3D ROC): 0.7436
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      1 │   106 │     0 │  17 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │      5 │  1961 │     3 │  68 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │   104 │     0 │  13 │
└───────┴────────┴───────┴───────┴─────┘
The count of True Accepted is: 1962
The count of False Accepted is: 220
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8992
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8992
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8992

This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      1 │   106 │     0 │  17 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │      5 │  1961 │     3 │  68 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │   104 │     0 │  13 │
└───────┴────────┴───────┴───────┴─────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.12      0.01      0.02       107
           0       0.90      1.00      0.95      1969
           1       0.00      0.00      0.00       106

    accuracy                           0.90      2182
   macro avg       0.34      0.34      0.32      2182
weighted avg       0.82      0.90      0.86      2182

Accuracy: 0.9328
Rejection Rate: 0.0430
Micro TPR: 0.8992
Micro FPR: 0.0504
Macro TPR: 0.3351
Macro FPR: 0.3302


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1206
Macro Distance (3D ROC): 0.7436
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      1 │   106 │     0 │  17 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │      5 │  1961 │     3 │  68 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      2 │   104 │     0 │  13 │
└───────┴────────┴───────┴───────┴─────┘
The count of True Accepted is: 1962
The count of False Accepted is: 220
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8992
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8992
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8992


Improvements due to a rejection rate of 4.30%:
- Change of the Misclassification Cost: -0.62%
- Change of the ITE Accurancy: 1.01%
- Change of the 3D ROC (micro): -6.49%
- Change of the 3D ROC (macro): 2.96%

VARIANT TYPE 2A II: OPTIMIZATION OF DOUBLE BOUNDARIES BY MINIMIZING 3DROC  

ITE values witht a probability between the optimal underbound 0.45 and the optimal upperbound 0.55 are rejected This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      5 │   112 │     0 │   7 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │     11 │  1997 │    10 │  19 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      3 │   111 │     2 │   3 │
└───────┴────────┴───────┴───────┴─────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.26      0.04      0.07       117
           0       0.90      0.99      0.94      2018
           1       0.17      0.02      0.03       116

    accuracy                           0.89      2251
   macro avg       0.44      0.35      0.35      2251
weighted avg       0.83      0.89      0.85      2251

Accuracy: 0.9268
Rejection Rate: 0.0127
Micro TPR: 0.8903
Micro FPR: 0.0549
Macro TPR: 0.3499
Macro FPR: 0.3228


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1233
Macro Distance (3D ROC): 0.7260
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      5 │   112 │     0 │   7 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │     11 │  1997 │    10 │  19 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      3 │   111 │     2 │   3 │
└───────┴────────┴───────┴───────┴─────┘
The count of True Accepted is: 2004
The count of False Accepted is: 247
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8903
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8903
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8903

This matrix is the crosstab of the column ite and ite_reject.
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      5 │   112 │     0 │   7 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │     11 │  1997 │    10 │  19 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      3 │   111 │     2 │   3 │
└───────┴────────┴───────┴───────┴─────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.26      0.04      0.07       117
           0       0.90      0.99      0.94      2018
           1       0.17      0.02      0.03       116

    accuracy                           0.89      2251
   macro avg       0.44      0.35      0.35      2251
weighted avg       0.83      0.89      0.85      2251

Accuracy: 0.9268
Rejection Rate: 0.0127
Micro TPR: 0.8903
Micro FPR: 0.0549
Macro TPR: 0.3499
Macro FPR: 0.3228


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1233
Macro Distance (3D ROC): 0.7260
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬────────┬───────┬───────┬─────┐
│   ite │   -1.0 │   0.0 │   1.0 │   R │
├───────┼────────┼───────┼───────┼─────┤
│    -1 │      5 │   112 │     0 │   7 │
├───────┼────────┼───────┼───────┼─────┤
│     0 │     11 │  1997 │    10 │  19 │
├───────┼────────┼───────┼───────┼─────┤
│     1 │      3 │   111 │     2 │   3 │
└───────┴────────┴───────┴───────┴─────┘
The count of True Accepted is: 2004
The count of False Accepted is: 247
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.8903
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.8903
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.8903


Improvements due to a rejection rate of 1.27%:
- Change of the Misclassification Cost: -0.76%
- Change of the ITE Accurancy: 0.37%
- Change of the 3D ROC (micro): -4.17%
- Change of the 3D ROC (macro): 0.59%

REJECTION TYPE 2A: REJECTION BASED ON PROBABILITIES BY MINIMIZING MISCLASSIFICATION COSTS 

ITE values witht a probability between the optimal underbound 0.30629840756619764 and the optimal upperbound 0.6937015924338024 are rejected This matrix is the crosstab of the column ite and ite_reject.
┌───────┬───────┬─────┐
│   ite │   0.0 │   R │
├───────┼───────┼─────┤
│    -1 │    93 │  31 │
├───────┼───────┼─────┤
│     0 │  1869 │ 168 │
├───────┼───────┼─────┤
│     1 │    85 │  34 │
└───────┴───────┴─────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.00      0.00      0.00        93
           0       0.91      1.00      0.95      1869
           1       0.00      0.00      0.00        85

    accuracy                           0.91      2047
   macro avg       0.30      0.33      0.32      2047
weighted avg       0.83      0.91      0.87      2047

Accuracy: 0.9420
Rejection Rate: 0.1022
Micro TPR: 0.9130
Micro FPR: 0.0435
Macro TPR: 0.3333
Macro FPR: 0.3333


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1411
Macro Distance (3D ROC): 0.7523
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬───────┬─────┐
│   ite │   0.0 │   R │
├───────┼───────┼─────┤
│    -1 │    93 │  31 │
├───────┼───────┼─────┤
│     0 │  1869 │ 168 │
├───────┼───────┼─────┤
│     1 │    85 │  34 │
└───────┴───────┴─────┘
The count of True Accepted is: 1869
The count of False Accepted is: 178
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.9130
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.9130
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.9130

This matrix is the crosstab of the column ite and ite_reject.
┌───────┬───────┬─────┐
│   ite │   0.0 │   R │
├───────┼───────┼─────┤
│    -1 │    93 │  31 │
├───────┼───────┼─────┤
│     0 │  1869 │ 168 │
├───────┼───────┼─────┤
│     1 │    85 │  34 │
└───────┴───────┴─────┘

Part 1 of the evaluation: Evaluate ITE models by considering only accepted instances, excluding rejected ones 
              precision    recall  f1-score   support

          -1       0.00      0.00      0.00        93
           0       0.91      1.00      0.95      1869
           1       0.00      0.00      0.00        85

    accuracy                           0.91      2047
   macro avg       0.30      0.33      0.32      2047
weighted avg       0.83      0.91      0.87      2047

Accuracy: 0.9420
Rejection Rate: 0.1022
Micro TPR: 0.9130
Micro FPR: 0.0435
Macro TPR: 0.3333
Macro FPR: 0.3333


Part 2 of the evaluation: Assess ITE models by incorporating penalties for instances that are rejected.
Micro Distance (3D ROC): 0.1411
Macro Distance (3D ROC): 0.7523
This matrix is the crosstab of the column ite_correct (T/F) and ite_rejected (T/F).
┌───────┬───────┬─────┐
│   ite │   0.0 │   R │
├───────┼───────┼─────┤
│    -1 │    93 │  31 │
├───────┼───────┼─────┤
│     0 │  1869 │ 168 │
├───────┼───────┼─────┤
│     1 │    85 │  34 │
└───────┴───────┴─────┘
The count of True Accepted is: 1869
The count of False Accepted is: 178
The count of True Rejected is: 0
The count of False Rejected is: 0

Accurancy of the rejection ( How much is correclty accepted) ): 0.9130
Coverage of the rejection (how much is accepted) ): 1.0000
The two measures above are clearly competing (more rejected, higher accurancy

Prediction quality measures the predictor’s performance on the non-rejected examples: 0.9130
Rejection quality indicates the rejector’s ability to reject misclassified examples: 0.0000
Combined quality: 0.9130


Improvements due to a rejection rate of 10.22%:
- Change of the Misclassification Cost: -3.14%
- Change of the ITE Accurancy: 1.98%
- Change of the 3D ROC (micro): 8.91%
- Change of the 3D ROC (macro): 4.08%


Table of test_set (First 20 rows)
+-----------+-----------+-----------+-----------+-----------+----------+----------+------+------+------+--------------+---------------+----------+------------+-----------------+-------+------------------+------------------+---------------+----------+
| treatment | y_t1_pred | y_t1_prob | y_t0_pred | y_t0_prob | ite_pred | ite_prob | y_t0 | y_t1 | ite  |   category   | category_pred | cost_ite | ite_reject | cost_ite_reject |  ood  | y_t1_reject_prob | y_t0_reject_prob | y_reject_prob | y_reject |
+-----------+-----------+-----------+-----------+-----------+----------+----------+------+------+------+--------------+---------------+----------+------------+-----------------+-------+------------------+------------------+---------------+----------+
|     0     |    0.0    |   0.013   |    0.0    |  0.0563   |   0.0    | -0.0433  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.2642   |    0.0    |  0.3269   |   0.0    | -0.0627  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |       True       |     False     |  False   |
|     1     |    0.0    |  0.1425   |    0.0    |  0.1997   |   0.0    | -0.0573  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.0572   |    0.0    |  0.1185   |   0.0    | -0.0613  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     0     |    0.0    |   0.085   |    0.0    |  0.0846   |   0.0    |  0.0004  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | True  |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.4261   |    0.0    |  0.3989   |   0.0    |  0.0272  | 1.0  | 1.0  | 0.0  |  Sure Thing  |  Lost Cause   |    0     |     R      |        2        | False |       True       |       True       |     True      |   True   |
|     0     |    0.0    |  0.0131   |    0.0    |  0.0547   |   0.0    | -0.0416  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | True  |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.4274   |    0.0    |   0.461   |   0.0    | -0.0336  | 1.0  | 0.0  | -1.0 | Sleeping Dog |  Lost Cause   |    10    |     R      |        2        | False |       True       |       True       |     True      |   True   |
|     1     |    0.0    |   0.039   |    0.0    |  0.0926   |   0.0    | -0.0536  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | True  |      False       |      False       |     False     |  False   |
|     1     |    1.0    |  0.8208   |    1.0    |  0.8387   |   0.0    | -0.0179  | 1.0  | 1.0  | 0.0  |  Sure Thing  |  Sure Thing   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     1     |    0.0    |   0.024   |    0.0    |  0.0372   |   0.0    | -0.0132  | 1.0  | 0.0  | -1.0 | Sleeping Dog |  Lost Cause   |    10    |    0.0     |       10        | False |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.0569   |    0.0    |  0.0666   |   0.0    | -0.0097  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     0     |    0.0    |   0.053   |    0.0    |  0.0835   |   0.0    | -0.0305  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     0     |    0.0    |   0.073   |    0.0    |  0.0722   |   0.0    |  0.0008  | 1.0  | 1.0  | 0.0  |  Sure Thing  |  Lost Cause   |    0     |    0.0     |        0        | True  |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.0016   |    0.0    |  0.0055   |   0.0    | -0.0038  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | True  |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.1833   |    0.0    |  0.1878   |   0.0    | -0.0045  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.0069   |    0.0    |  0.0217   |   0.0    | -0.0148  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | True  |      False       |      False       |     False     |  False   |
|     1     |    0.0    |  0.0337   |    0.0    |  0.0486   |   0.0    |  -0.015  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.0446   |    0.0    |  0.0594   |   0.0    | -0.0148  | 0.0  | 0.0  | 0.0  |  Lost Cause  |  Lost Cause   |    0     |    0.0     |        0        | False |      False       |      False       |     False     |  False   |
|     0     |    0.0    |  0.4628   |    0.0    |  0.3961   |   0.0    |  0.0668  | 1.0  | 1.0  | 0.0  |  Sure Thing  |  Lost Cause   |    0     |     R      |        2        | False |       True       |       True       |     True      |   True   |
+-----------+-----------+-----------+-----------+-----------+----------+----------+------+------+------+--------------+---------------+----------+------------+-----------------+-------+------------------+------------------+---------------+----------+

Table of results of the experiments
╭──────────────┬─────────────────────┬───────────────────────┬────────────┬──────────────────┬─────────────┬─────────────┬─────────────┬─────────────╮
│   Experiment │ Architecture Type   │ Rejection Type        │   Accuracy │   Rejection Rate │   Micro TPR │   Micro FPR │   Macro TPR │   Macro FPR │
├──────────────┼─────────────────────┼───────────────────────┼────────────┼──────────────────┼─────────────┼─────────────┼─────────────┼─────────────┤
│            0 │ No Rejection        │ No Rejection          │     0.9234 │           0      │      0.8851 │      0.0575 │      0.3534 │      0.3204 │
├──────────────┼─────────────────────┼───────────────────────┼────────────┼──────────────────┼─────────────┼─────────────┼─────────────┼─────────────┤
│            1 │ separated           │ OOD - KNN             │     0.9258 │           0.1649 │      0.8887 │      0.0557 │      0.356  │      0.3193 │
├──────────────┼─────────────────────┼───────────────────────┼────────────┼──────────────────┼─────────────┼─────────────┼─────────────┼─────────────┤
│            2 │ separated           │ OCSVM                 │     0.9265 │           0.511  │      0.8897 │      0.0552 │      0.3638 │      0.3167 │
├──────────────┼─────────────────────┼───────────────────────┼────────────┼──────────────────┼─────────────┼─────────────┼─────────────┼─────────────┤
│            3 │ separated           │ Scores Model          │     0.9234 │           0      │      0.8851 │      0.0575 │      0.3534 │      0.3204 │
├──────────────┼─────────────────────┼───────────────────────┼────────────┼──────────────────┼─────────────┼─────────────┼─────────────┼─────────────┤
│            4 │ dependent           │ prob symetric bounds  │     0.9328 │           0.043  │      0.8992 │      0.0504 │      0.3351 │      0.3302 │
├──────────────┼─────────────────────┼───────────────────────┼────────────┼──────────────────┼─────────────┼─────────────┼─────────────┼─────────────┤
│            5 │ dependent           │ prob asymetric bounds │     0.9268 │           0.0127 │      0.8903 │      0.0549 │      0.3499 │      0.3228 │
├──────────────┼─────────────────────┼───────────────────────┼────────────┼──────────────────┼─────────────┼─────────────┼─────────────┼─────────────┤
│            6 │ dependent           │ prob miscost          │     0.942  │           0.1022 │      0.913  │      0.0435 │      0.3333 │      0.3333 │
╰──────────────┴─────────────────────┴───────────────────────┴────────────┴──────────────────┴─────────────┴─────────────┴─────────────┴─────────────╯

Table of results of the experiments
╭───────────────────┬──────────────┬───────────┬───────────┬──────────────┬──────────────────────┬───────────────────────┬──────────────╮
│ Experiment        │ 0            │ 1         │ 2         │ 3            │ 4                    │ 5                     │ 6            │
├───────────────────┼──────────────┼───────────┼───────────┼──────────────┼──────────────────────┼───────────────────────┼──────────────┤
│ Architecture Type │ No Rejection │ separated │ separated │ separated    │ dependent            │ dependent             │ dependent    │
├───────────────────┼──────────────┼───────────┼───────────┼──────────────┼──────────────────────┼───────────────────────┼──────────────┤
│ Rejection Type    │ No Rejection │ OOD - KNN │ OCSVM     │ Scores Model │ prob symetric bounds │ prob asymetric bounds │ prob miscost │
├───────────────────┼──────────────┼───────────┼───────────┼──────────────┼──────────────────────┼───────────────────────┼──────────────┤
│ Accuracy          │ 0.9234       │ 0.9258    │ 0.9265    │ 0.9234       │ 0.9328               │ 0.9268                │ 0.942        │
├───────────────────┼──────────────┼───────────┼───────────┼──────────────┼──────────────────────┼───────────────────────┼──────────────┤
│ Rejection Rate    │ 0.0          │ 0.1649    │ 0.511     │ 0.0          │ 0.043                │ 0.0127                │ 0.1022       │
├───────────────────┼──────────────┼───────────┼───────────┼──────────────┼──────────────────────┼───────────────────────┼──────────────┤
│ Micro TPR         │ 0.8851       │ 0.8887    │ 0.8897    │ 0.8851       │ 0.8992               │ 0.8903                │ 0.913        │
├───────────────────┼──────────────┼───────────┼───────────┼──────────────┼──────────────────────┼───────────────────────┼──────────────┤
│ Micro FPR         │ 0.0575       │ 0.0557    │ 0.0552    │ 0.0575       │ 0.0504               │ 0.0549                │ 0.0435       │
├───────────────────┼──────────────┼───────────┼───────────┼──────────────┼──────────────────────┼───────────────────────┼──────────────┤
│ Macro TPR         │ 0.3534       │ 0.356     │ 0.3638    │ 0.3534       │ 0.3351               │ 0.3499                │ 0.3333       │
├───────────────────┼──────────────┼───────────┼───────────┼──────────────┼──────────────────────┼───────────────────────┼──────────────┤
│ Macro FPR         │ 0.3204       │ 0.3193    │ 0.3167    │ 0.3204       │ 0.3302               │ 0.3228                │ 0.3333       │
╰───────────────────┴──────────────┴───────────┴───────────┴──────────────┴──────────────────────┴───────────────────────┴──────────────╯